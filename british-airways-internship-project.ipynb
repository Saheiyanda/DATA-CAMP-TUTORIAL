{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project : To scrape cutomer reviews of british airlines and analyse the data collected for usable insights\n",
    "\n",
    "#### Internship project for FORAGE British Airways Data Science project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "### Web scraping and analysis\n",
    "\n",
    "Scraping data from Skytrax\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use Python and BeautifulSoup to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:20.838191Z",
     "iopub.status.busy": "2023-11-23T19:57:20.837607Z",
     "iopub.status.idle": "2023-11-23T19:57:23.639876Z",
     "shell.execute_reply": "2023-11-23T19:57:23.637515Z",
     "shell.execute_reply.started": "2023-11-23T19:57:20.838080Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from string import digits\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:23.648140Z",
     "iopub.status.busy": "2023-11-23T19:57:23.645418Z",
     "iopub.status.idle": "2023-11-23T19:57:25.502235Z",
     "shell.execute_reply": "2023-11-23T19:57:25.501161Z",
     "shell.execute_reply.started": "2023-11-23T19:57:23.648059Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:25.505072Z",
     "iopub.status.busy": "2023-11-23T19:57:25.504245Z",
     "iopub.status.idle": "2023-11-23T19:57:25.512073Z",
     "shell.execute_reply": "2023-11-23T19:57:25.510398Z",
     "shell.execute_reply.started": "2023-11-23T19:57:25.505019Z"
    }
   },
   "outputs": [],
   "source": [
    "# #scraping data fron skytrax\n",
    "# base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "# pages = 36\n",
    "# page_size = 100\n",
    "\n",
    "# reviews = []\n",
    "# stars = []\n",
    "# date = []\n",
    "# country = []\n",
    "\n",
    "# # for i in range(1, pages + 1):\n",
    "# for i in range(1, pages + 1):\n",
    "\n",
    "#     print(f\"Scraping page {i}\")\n",
    "\n",
    "#     # Create URL to collect links from paginated data\n",
    "#     url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "#     # Collect HTML data from this page\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Parse content\n",
    "#     content = response.content\n",
    "#     parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "#     for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "#         reviews.append(para.get_text())\n",
    "\n",
    "#     for para in parsed_content.find_all(\"time\"):\n",
    "#         date.append(para.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:25.515626Z",
     "iopub.status.busy": "2023-11-23T19:57:25.515178Z",
     "iopub.status.idle": "2023-11-23T19:57:46.911012Z",
     "shell.execute_reply": "2023-11-23T19:57:46.909918Z",
     "shell.execute_reply.started": "2023-11-23T19:57:25.515589Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the reviews in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:46.913554Z",
     "iopub.status.busy": "2023-11-23T19:57:46.912796Z",
     "iopub.status.idle": "2023-11-23T19:57:46.996209Z",
     "shell.execute_reply": "2023-11-23T19:57:46.994765Z",
     "shell.execute_reply.started": "2023-11-23T19:57:46.913511Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"reviews\":reviews}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:46.999314Z",
     "iopub.status.busy": "2023-11-23T19:57:46.998397Z",
     "iopub.status.idle": "2023-11-23T19:57:47.054517Z",
     "shell.execute_reply": "2023-11-23T19:57:47.053167Z",
     "shell.execute_reply.started": "2023-11-23T19:57:46.999260Z"
    }
   },
   "outputs": [],
   "source": [
    "# downloading file\n",
    "df.to_csv(\"BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK 2\n",
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:47.056663Z",
     "iopub.status.busy": "2023-11-23T19:57:47.056231Z",
     "iopub.status.idle": "2023-11-23T19:57:47.089728Z",
     "shell.execute_reply": "2023-11-23T19:57:47.088190Z",
     "shell.execute_reply.started": "2023-11-23T19:57:47.056626Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"BA_reviews.csv\"\n",
    "ds = pd.read_csv(csv_path)\n",
    "ds.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(ds['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:47.091985Z",
     "iopub.status.busy": "2023-11-23T19:57:47.091630Z",
     "iopub.status.idle": "2023-11-23T19:57:47.128642Z",
     "shell.execute_reply": "2023-11-23T19:57:47.126830Z",
     "shell.execute_reply.started": "2023-11-23T19:57:47.091954Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.info()\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values/ missing values in the dataset.\n",
    "The dataset contains 1000 unique entries.\n",
    "Removing (âœ… Trip Verified | and Not Verified | ) to clean the data.\n",
    "Removing any leading or trailing spaces.\n",
    "Turning the review string to all lower case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:47.131648Z",
     "iopub.status.busy": "2023-11-23T19:57:47.130647Z",
     "iopub.status.idle": "2023-11-23T19:57:47.151921Z",
     "shell.execute_reply": "2023-11-23T19:57:47.150197Z",
     "shell.execute_reply.started": "2023-11-23T19:57:47.131584Z"
    }
   },
   "outputs": [],
   "source": [
    "ds['reviews'] = ds['reviews'].str.strip()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:47.158855Z",
     "iopub.status.busy": "2023-11-23T19:57:47.158395Z",
     "iopub.status.idle": "2023-11-23T19:57:48.329073Z",
     "shell.execute_reply": "2023-11-23T19:57:48.328047Z",
     "shell.execute_reply.started": "2023-11-23T19:57:47.158815Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.reviews= ds.reviews.str.replace('.*\\|', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.331085Z",
     "iopub.status.busy": "2023-11-23T19:57:48.330509Z",
     "iopub.status.idle": "2023-11-23T19:57:48.346047Z",
     "shell.execute_reply": "2023-11-23T19:57:48.344534Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.331050Z"
    }
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.348419Z",
     "iopub.status.busy": "2023-11-23T19:57:48.348033Z",
     "iopub.status.idle": "2023-11-23T19:57:48.368227Z",
     "shell.execute_reply": "2023-11-23T19:57:48.366641Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.348386Z"
    }
   },
   "outputs": [],
   "source": [
    "ds['reviews']= ds['reviews'].str.lower()\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "#### Sentiment analysis of reviews using nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctutaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.369909Z",
     "iopub.status.busy": "2023-11-23T19:57:48.369516Z",
     "iopub.status.idle": "2023-11-23T19:57:48.381777Z",
     "shell.execute_reply": "2023-11-23T19:57:48.380304Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.369875Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_new = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.384263Z",
     "iopub.status.busy": "2023-11-23T19:57:48.383716Z",
     "iopub.status.idle": "2023-11-23T19:57:48.402648Z",
     "shell.execute_reply": "2023-11-23T19:57:48.401047Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.384224Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.404977Z",
     "iopub.status.busy": "2023-11-23T19:57:48.404079Z",
     "iopub.status.idle": "2023-11-23T19:57:48.458759Z",
     "shell.execute_reply": "2023-11-23T19:57:48.457241Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.404940Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "ds_new['reviews'] = ds_new['reviews'].str.replace('[^\\w\\s]','')\n",
    "print(ds_new['reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.460713Z",
     "iopub.status.busy": "2023-11-23T19:57:48.460308Z",
     "iopub.status.idle": "2023-11-23T19:57:48.477540Z",
     "shell.execute_reply": "2023-11-23T19:57:48.475725Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.460679Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:48.481232Z",
     "iopub.status.busy": "2023-11-23T19:57:48.479842Z",
     "iopub.status.idle": "2023-11-23T19:57:49.719311Z",
     "shell.execute_reply": "2023-11-23T19:57:49.717726Z",
     "shell.execute_reply.started": "2023-11-23T19:57:48.481173Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "print(ds_new.iloc[1,1])\n",
    "ds_new['reviews'] = ds_new.apply(lambda row: nltk.word_tokenize(row['reviews']), axis=1)\n",
    "print(ds_new.iloc[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:49.721609Z",
     "iopub.status.busy": "2023-11-23T19:57:49.721173Z",
     "iopub.status.idle": "2023-11-23T19:57:49.728521Z",
     "shell.execute_reply": "2023-11-23T19:57:49.726920Z",
     "shell.execute_reply.started": "2023-11-23T19:57:49.721569Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_tksd = ds_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:49.732122Z",
     "iopub.status.busy": "2023-11-23T19:57:49.730548Z",
     "iopub.status.idle": "2023-11-23T19:57:49.772580Z",
     "shell.execute_reply": "2023-11-23T19:57:49.771081Z",
     "shell.execute_reply.started": "2023-11-23T19:57:49.732063Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_tksd['reviews'] = ds_tksd['reviews'].apply(lambda x: ' '.join([word for word in x if word not in (stop_words)]))\n",
    "print(ds_tksd.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate polarity to gather sentiment tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:49.774784Z",
     "iopub.status.busy": "2023-11-23T19:57:49.774357Z",
     "iopub.status.idle": "2023-11-23T19:57:50.769935Z",
     "shell.execute_reply": "2023-11-23T19:57:50.768557Z",
     "shell.execute_reply.started": "2023-11-23T19:57:49.774747Z"
    }
   },
   "outputs": [],
   "source": [
    "def polarity_calc(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    \n",
    "def tag_cal(num):\n",
    "    if num<0:\n",
    "        return 'Negative'\n",
    "    elif num>0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "        \n",
    "    \n",
    "ds_tksd['polarity'] = ds_tksd['reviews'].apply(polarity_calc)\n",
    "\n",
    "\n",
    "ds_tksd['tag'] = ds_tksd['polarity'].apply(tag_cal)\n",
    "\n",
    "\n",
    "print(ds_tksd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4 \n",
    "#### Analyze "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of various types of tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:50.772115Z",
     "iopub.status.busy": "2023-11-23T19:57:50.771727Z",
     "iopub.status.idle": "2023-11-23T19:57:50.785717Z",
     "shell.execute_reply": "2023-11-23T19:57:50.784046Z",
     "shell.execute_reply.started": "2023-11-23T19:57:50.772082Z"
    }
   },
   "outputs": [],
   "source": [
    "(ds_tksd.groupby('tag').size()/ds_tksd['tag'].count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of each kind of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5\n",
    "#### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:50.787708Z",
     "iopub.status.busy": "2023-11-23T19:57:50.787327Z",
     "iopub.status.idle": "2023-11-23T19:57:52.005026Z",
     "shell.execute_reply": "2023-11-23T19:57:52.004044Z",
     "shell.execute_reply.started": "2023-11-23T19:57:50.787676Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \" \"\n",
    "for ind in ds_tksd.index:\n",
    "    if ds_tksd['tag'][ind] == \"Positive\":\n",
    "        text = text + ds_tksd['reviews'][ind]\n",
    "      \n",
    "wordcloud_positive = WordCloud().generate(text)\n",
    "\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:52.006432Z",
     "iopub.status.busy": "2023-11-23T19:57:52.006069Z",
     "iopub.status.idle": "2023-11-23T19:57:53.195226Z",
     "shell.execute_reply": "2023-11-23T19:57:53.193913Z",
     "shell.execute_reply.started": "2023-11-23T19:57:52.006400Z"
    }
   },
   "outputs": [],
   "source": [
    "text2= \" \"        \n",
    "for ind in ds_tksd.index:\n",
    "    if ds_tksd['tag'][ind] == \"Negative\":\n",
    "        text2 = text2 + ds_tksd['reviews'][ind]  \n",
    "wordcloud_negative = WordCloud().generate(text2)\n",
    "plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.197279Z",
     "iopub.status.busy": "2023-11-23T19:57:53.196901Z",
     "iopub.status.idle": "2023-11-23T19:57:53.456802Z",
     "shell.execute_reply": "2023-11-23T19:57:53.455755Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.197243Z"
    }
   },
   "outputs": [],
   "source": [
    "# ds_tksd['tag'].value_counts().plot(kind='bar')\n",
    "sns.set(font_scale = 1.4)\n",
    "ds_tksd['tag'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\n",
    "plt.xlabel(\"Sentiment\", labelpad=14)\n",
    "plt.ylabel(\"No of reviews\", labelpad=14)\n",
    "plt.title(\"Sentient counts\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.459778Z",
     "iopub.status.busy": "2023-11-23T19:57:53.458832Z",
     "iopub.status.idle": "2023-11-23T19:57:53.611082Z",
     "shell.execute_reply": "2023-11-23T19:57:53.609694Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.459725Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.pie(ds_tksd['tag'].value_counts(), labels = ds_tksd['tag'].value_counts().index, explode = (0, 0, 0.25), autopct='%1.1f%%', shadow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this analysis with vader analysis based on the lemmatized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.614315Z",
     "iopub.status.busy": "2023-11-23T19:57:53.613427Z",
     "iopub.status.idle": "2023-11-23T19:57:53.701002Z",
     "shell.execute_reply": "2023-11-23T19:57:53.699299Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.614266Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"This punkt tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, \n",
    "collocations, and words that start sentences. \"\"\"\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk import pos_tag\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.702962Z",
     "iopub.status.busy": "2023-11-23T19:57:53.702558Z",
     "iopub.status.idle": "2023-11-23T19:57:53.756994Z",
     "shell.execute_reply": "2023-11-23T19:57:53.755657Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.702927Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_final = ds.copy()\n",
    "ds_final['reviews'] = ds_final['reviews'].str.replace('[^\\w\\s]','')\n",
    "ds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.767601Z",
     "iopub.status.busy": "2023-11-23T19:57:53.767126Z",
     "iopub.status.idle": "2023-11-23T19:57:53.798034Z",
     "shell.execute_reply": "2023-11-23T19:57:53.796510Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.767561Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.801149Z",
     "iopub.status.busy": "2023-11-23T19:57:53.800633Z",
     "iopub.status.idle": "2023-11-23T19:57:53.905714Z",
     "shell.execute_reply": "2023-11-23T19:57:53.904347Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.801100Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "# Cleaning the text in the review column\n",
    "ds_final['Cleaned Reviews'] = ds_final['reviews'].apply(clean)\n",
    "ds_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T19:57:53.907664Z",
     "iopub.status.busy": "2023-11-23T19:57:53.907262Z",
     "iopub.status.idle": "2023-11-23T19:58:32.891339Z",
     "shell.execute_reply": "2023-11-23T19:58:32.888994Z",
     "shell.execute_reply.started": "2023-11-23T19:57:53.907619Z"
    }
   },
   "outputs": [],
   "source": [
    "#The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora.\n",
    "\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    #print(tags)\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "          newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "          #print(tag[0])\n",
    "          #print(pos_dict.get(tag[0]))\n",
    "    return newlist \n",
    "\n",
    "ds_final['POS tagged'] = ds_final['Cleaned Reviews'].apply(token_stop_pos)\n",
    "ds_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.892622Z",
     "iopub.status.idle": "2023-11-23T19:58:32.893082Z",
     "shell.execute_reply": "2023-11-23T19:58:32.892879Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.892859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtaining the stem words â€“ Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "     if not pos:\n",
    "        lemma = word\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "     else:\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "ds_final['Lemma'] = ds_final['POS tagged'].apply(lemmatize)\n",
    "ds_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.895283Z",
     "iopub.status.idle": "2023-11-23T19:58:32.895903Z",
     "shell.execute_reply": "2023-11-23T19:58:32.895697Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.895674Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_final[['reviews','Lemma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using VADER\n",
    "\n",
    "VADER stands for Valence Aware Dictionary and Sentiment Reasoner.\n",
    "\n",
    "Vader sentiment not only tells if the statement is positive or negative along with the intensity of emotion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.897614Z",
     "iopub.status.idle": "2023-11-23T19:58:32.898055Z",
     "shell.execute_reply": "2023-11-23T19:58:32.897863Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.897843Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.899666Z",
     "iopub.status.idle": "2023-11-23T19:58:32.900068Z",
     "shell.execute_reply": "2023-11-23T19:58:32.899889Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.899870Z"
    }
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "\n",
    "ds_final['Sentiment'] = ds_final['Lemma'].apply(vadersentimentanalysis)\n",
    "\n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound < 0 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "ds_final['Analysis'] = ds_final['Sentiment'].apply(vader_analysis)\n",
    "ds_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.902033Z",
     "iopub.status.idle": "2023-11-23T19:58:32.902514Z",
     "shell.execute_reply": "2023-11-23T19:58:32.902286Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.902266Z"
    }
   },
   "outputs": [],
   "source": [
    "vader_counts = ds_final['Analysis'].value_counts()\n",
    "vader_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.904570Z",
     "iopub.status.idle": "2023-11-23T19:58:32.905002Z",
     "shell.execute_reply": "2023-11-23T19:58:32.904811Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.904791Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Reviews Analysis\")\n",
    "plt.pie(vader_counts.values, labels = vader_counts.index, explode = (0, 0, 0.25), autopct='%1.1f%%', shadow=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.907053Z",
     "iopub.status.idle": "2023-11-23T19:58:32.907529Z",
     "shell.execute_reply": "2023-11-23T19:58:32.907303Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.907282Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        max_font_size=30,\n",
    "        scale=3,\n",
    "        random_state=1)\n",
    "\n",
    "    wordcloud=wordcloud.generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(ds_final.Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.909045Z",
     "iopub.status.idle": "2023-11-23T19:58:32.909776Z",
     "shell.execute_reply": "2023-11-23T19:58:32.909574Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.909552Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.911436Z",
     "iopub.status.idle": "2023-11-23T19:58:32.911892Z",
     "shell.execute_reply": "2023-11-23T19:58:32.911703Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.911683Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.913050Z",
     "iopub.status.idle": "2023-11-23T19:58:32.913509Z",
     "shell.execute_reply": "2023-11-23T19:58:32.913291Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.913271Z"
    }
   },
   "outputs": [],
   "source": [
    "data['verified?'] = data['reviews'].apply(lambda x: x.split('|')[0])\n",
    "data['reviews'] = data['reviews'].str.replace('.*\\|', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.914926Z",
     "iopub.status.idle": "2023-11-23T19:58:32.916113Z",
     "shell.execute_reply": "2023-11-23T19:58:32.915907Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.915883Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.918780Z",
     "iopub.status.idle": "2023-11-23T19:58:32.919230Z",
     "shell.execute_reply": "2023-11-23T19:58:32.919028Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.919008Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = data[data['verified?'].str.contains('Verified')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.920872Z",
     "iopub.status.idle": "2023-11-23T19:58:32.921309Z",
     "shell.execute_reply": "2023-11-23T19:58:32.921107Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.921087Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test.loc[(data_test['verified?'] != 'âœ… Trip Verified ') & (data_test['verified?'] != None),'verified?'] = 'Not Verified'\n",
    "data_test.loc[data_test['verified?'] == 'âœ… Trip Verified ','verified?'] = 'Trip Verified'\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.922854Z",
     "iopub.status.idle": "2023-11-23T19:58:32.923281Z",
     "shell.execute_reply": "2023-11-23T19:58:32.923084Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.923064Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test['verified?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.925998Z",
     "iopub.status.idle": "2023-11-23T19:58:32.926412Z",
     "shell.execute_reply": "2023-11-23T19:58:32.926226Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.926208Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.927870Z",
     "iopub.status.idle": "2023-11-23T19:58:32.928301Z",
     "shell.execute_reply": "2023-11-23T19:58:32.928102Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.928082Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy, gensim\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.930739Z",
     "iopub.status.idle": "2023-11-23T19:58:32.931122Z",
     "shell.execute_reply": "2023-11-23T19:58:32.930947Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.930930Z"
    }
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data['reviews'].tolist()))\n",
    "\n",
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.932733Z",
     "iopub.status.idle": "2023-11-23T19:58:32.933280Z",
     "shell.execute_reply": "2023-11-23T19:58:32.933062Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.933027Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.934968Z",
     "iopub.status.idle": "2023-11-23T19:58:32.935398Z",
     "shell.execute_reply": "2023-11-23T19:58:32.935206Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.935187Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.936790Z",
     "iopub.status.idle": "2023-11-23T19:58:32.937216Z",
     "shell.execute_reply": "2023-11-23T19:58:32.937021Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.937001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.938921Z",
     "iopub.status.idle": "2023-11-23T19:58:32.939371Z",
     "shell.execute_reply": "2023-11-23T19:58:32.939165Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.939144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=4,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.942620Z",
     "iopub.status.idle": "2023-11-23T19:58:32.943061Z",
     "shell.execute_reply": "2023-11-23T19:58:32.942874Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.942854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.945711Z",
     "iopub.status.idle": "2023-11-23T19:58:32.946815Z",
     "shell.execute_reply": "2023-11-23T19:58:32.946417Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.946381Z"
    }
   },
   "outputs": [],
   "source": [
    "df_document_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.948705Z",
     "iopub.status.idle": "2023-11-23T19:58:32.949364Z",
     "shell.execute_reply": "2023-11-23T19:58:32.949056Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.949027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.951394Z",
     "iopub.status.idle": "2023-11-23T19:58:32.952047Z",
     "shell.execute_reply": "2023-11-23T19:58:32.951764Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.951736Z"
    }
   },
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.954672Z",
     "iopub.status.idle": "2023-11-23T19:58:32.956320Z",
     "shell.execute_reply": "2023-11-23T19:58:32.956075Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.956047Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(range(1,5,1),[25,573,169,233], color=\"blue\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.title(\"Number of reviews per topic\")\n",
    "x_labels = ([\"Positive\\nCustomer\\nExperience\", \"In-flight\\namenities\\nand services\",\n",
    "            \"Boarding\\n& departure\\nprocess\",\"Booking\\n& refund\\nprocess\"])\n",
    "plt.xticks(range(1,5), x_labels)\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.957595Z",
     "iopub.status.idle": "2023-11-23T19:58:32.958001Z",
     "shell.execute_reply": "2023-11-23T19:58:32.957818Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.957799Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.960316Z",
     "iopub.status.idle": "2023-11-23T19:58:32.960780Z",
     "shell.execute_reply": "2023-11-23T19:58:32.960563Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.960535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(lda_model.components_)\n",
    "\n",
    "# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames\n",
    "\n",
    "# View\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.962657Z",
     "iopub.status.idle": "2023-11-23T19:58:32.963083Z",
     "shell.execute_reply": "2023-11-23T19:58:32.962899Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.962879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=15)        \n",
    "\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.964309Z",
     "iopub.status.idle": "2023-11-23T19:58:32.965055Z",
     "shell.execute_reply": "2023-11-23T19:58:32.964619Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.964587Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.968569Z",
     "iopub.status.idle": "2023-11-23T19:58:32.969238Z",
     "shell.execute_reply": "2023-11-23T19:58:32.968924Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.968892Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sentiment'] = data['reviews'].apply(lambda x: sentiment_pipeline(x, max_length=512, truncation=True)[0][\"label\"])\n",
    "data['confidence'] = data['reviews'].apply(lambda x: sentiment_pipeline(x, max_length=512, truncation=True)[0][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.971256Z",
     "iopub.status.idle": "2023-11-23T19:58:32.971965Z",
     "shell.execute_reply": "2023-11-23T19:58:32.971650Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.971618Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.974141Z",
     "iopub.status.idle": "2023-11-23T19:58:32.974823Z",
     "shell.execute_reply": "2023-11-23T19:58:32.974516Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.974486Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby('verified?')['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.977065Z",
     "iopub.status.idle": "2023-11-23T19:58:32.977636Z",
     "shell.execute_reply": "2023-11-23T19:58:32.977377Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.977356Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby('verified?')['sentiment'].value_counts().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.979496Z",
     "iopub.status.idle": "2023-11-23T19:58:32.979922Z",
     "shell.execute_reply": "2023-11-23T19:58:32.979737Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.979718Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.981150Z",
     "iopub.status.idle": "2023-11-23T19:58:32.981628Z",
     "shell.execute_reply": "2023-11-23T19:58:32.981393Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.981373Z"
    }
   },
   "outputs": [],
   "source": [
    "topics_ = df_document_topic['dominant_topic'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.983741Z",
     "iopub.status.idle": "2023-11-23T19:58:32.984189Z",
     "shell.execute_reply": "2023-11-23T19:58:32.983995Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.983974Z"
    }
   },
   "outputs": [],
   "source": [
    "data['topic'] = topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.985600Z",
     "iopub.status.idle": "2023-11-23T19:58:32.986040Z",
     "shell.execute_reply": "2023-11-23T19:58:32.985836Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.985815Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.987241Z",
     "iopub.status.idle": "2023-11-23T19:58:32.987697Z",
     "shell.execute_reply": "2023-11-23T19:58:32.987504Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.987481Z"
    }
   },
   "outputs": [],
   "source": [
    "data[data['verified?'] == 'âœ… Trip Verified '].groupby(['topic'])['sentiment'].value_counts().unstack().plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.989037Z",
     "iopub.status.idle": "2023-11-23T19:58:32.989753Z",
     "shell.execute_reply": "2023-11-23T19:58:32.989302Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.989280Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.992655Z",
     "iopub.status.idle": "2023-11-23T19:58:32.993635Z",
     "shell.execute_reply": "2023-11-23T19:58:32.993104Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.993071Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Convert to lower case\n",
    "data['review_text'] = data['reviews'].str.lower()\n",
    "\n",
    "# Remove punctuation and numbers\n",
    "data['review_text'] = data['review_text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation + string.digits)))\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend(['british','airway','airline','ba','flight'])\n",
    "stop_words = set(stop_words)\n",
    "data['review_text'] = data['review_text'].apply(lambda x: \" \".join(word for word in x.split() if word.lower() not in stop_words))\n",
    "\n",
    "\n",
    "# Perform lemmatization \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['review_text'] = data['review_text'].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) \n",
    "                                                                    for word in x.split() if len(word)> 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.995976Z",
     "iopub.status.idle": "2023-11-23T19:58:32.996556Z",
     "shell.execute_reply": "2023-11-23T19:58:32.996299Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.996275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get bigrams and their frequency\n",
    "bigrams = list(ngrams(data[data['sentiment'] == 'POSITIVE']['review_text'].str.cat(sep=' ').split(), 2))\n",
    "bigrams_fd = FreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:32.998797Z",
     "iopub.status.idle": "2023-11-23T19:58:32.999321Z",
     "shell.execute_reply": "2023-11-23T19:58:32.999092Z",
     "shell.execute_reply.started": "2023-11-23T19:58:32.999070Z"
    }
   },
   "outputs": [],
   "source": [
    "bigrams_fd = {'_'.join(bigram): freq for bigram, freq in bigrams_fd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:33.001968Z",
     "iopub.status.idle": "2023-11-23T19:58:33.003034Z",
     "shell.execute_reply": "2023-11-23T19:58:33.002807Z",
     "shell.execute_reply.started": "2023-11-23T19:58:33.002781Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, min_font_size = 10, background_color ='white',)\n",
    "# Generate the word cloud\n",
    "wordcloud.generate_from_frequencies(bigrams_fd)\n",
    "\n",
    "# Show the word cloud\n",
    "plt.figure(figsize=(10,10), facecolor = None)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:33.006041Z",
     "iopub.status.idle": "2023-11-23T19:58:33.006834Z",
     "shell.execute_reply": "2023-11-23T19:58:33.006493Z",
     "shell.execute_reply.started": "2023-11-23T19:58:33.006439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get bigrams and their frequency\n",
    "bigrams_ng = list(ngrams(data[data['sentiment'] == 'NEGATIVE']['review_text'].str.cat(sep=' ').split(), 2))\n",
    "bigrams_fd_ng = FreqDist(bigrams_ng)\n",
    "bigrams_fd_ng = {'_'.join(bigram): freq for bigram, freq in bigrams_fd_ng.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-23T19:58:33.009103Z",
     "iopub.status.idle": "2023-11-23T19:58:33.009759Z",
     "shell.execute_reply": "2023-11-23T19:58:33.009462Z",
     "shell.execute_reply.started": "2023-11-23T19:58:33.009417Z"
    }
   },
   "outputs": [],
   "source": [
    "igrams_fd_ng = FreqDist(bigrams_ng)\n",
    "bigrams_fd_ng = {''.join(bigram): freq for bigram, freq in bigrams_fd_ng.items()}\n",
    "wordcloud = WordCloud(width=800, height=400, min_font_size = 10, background_color ='white',)\n",
    "# Generate the word cloud\n",
    "wordcloud.generate_from_frequencies(bigrams_fd_ng)\n",
    "\n",
    "# Show the word cloud\n",
    "plt.figure(figsize=(10,10), facecolor = None)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30301,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
